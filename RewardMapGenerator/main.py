import numpy as np
from tqdm import tqdm
import gc

from multiprocessing import Pool, cpu_count

from Envs import AstEnv, Runner

#################### Main Code for Reward Map Generating ####################
    # UPDATED : 25.11.19
    # Data Format Changed : shape 1012
    # CPU-Parallel Code
#############################################################################


#################### Settings ####################
DATA_PATH = "C:/Users/dlgkr/OneDrive/Desktop/code/astronomy/asteroid_AI/data/data_pole_axis_total_preprocessed.npz"
SAVE_PATH = "C:/Users/dlgkr/OneDrive/Desktop/code/astronomy/asteroid_AI/data/"
 
N_set = (40, 20)
lightcurve_unit_len = 100
reward_domain = [-100, 50] #-20, 50

# Global Variables for each Worker Processors
X_total = None
ell_total = None
START_IDX = None
REWARD_DOMAIN = None
N_SET = None
LC_UNIT_LEN = None


#################### Functions ####################

def worker_init(data_path, start_idx, final_idx, reward_domain, n_set, lc_unit_len):
    # init. funciton : excuted at the start of each process
    # load the npz file, and save to global var. only the part we need
    global X_total, ell_total, START_IDX, REWARD_DOMAIN, N_SET, LC_UNIT_LEN

    START_IDX = start_idx
    REWARD_DOMAIN = reward_domain
    N_SET = n_set
    LC_UNIT_LEN = lc_unit_len

    total_data = np.load(data_path)
    X_full = total_data["lc_arr"]
    ell_full = total_data["ell_arr"]

    X_total = X_full[start_idx:final_idx].copy()
    ell_total = ell_full[start_idx:final_idx].copy()


def run_one(local_i):
    # Run one environment for index local_i
    # Returns:
    #   data_set_arr: dataset generated by Runner (or None if ell_err)
    #   is_ell_err: True if ellipsoid initialization failed
    #   reward0_i: initial reward (reward0)
    #   global_i: global index (start_idx + local_i)
    global X_total, ell_total, START_IDX, REWARD_DOMAIN, N_SET, LC_UNIT_LEN

    global_i = START_IDX + local_i
    x = X_total[local_i]
    ell = ell_total[local_i]

    target_lc = x[:-9]
    lc_info = x[-9:]

    # Build environment
    env = AstEnv(
        target_lc=target_lc,
        lc_info=lc_info,
        reward_domain=REWARD_DOMAIN,
        N_set=N_SET,
        lc_unit_len=LC_UNIT_LEN,
        ell_init=(True, ell)
    )

    # If ellipsoid initialization fails, return flag
    if env.ell_err:
        return None, True, env.reward0, global_i

    state_dim = (env.Ntheta // env.ast_obs_unit_step) * (env.Nphi // env.ast_obs_unit_step) \
                + 2 * (LC_UNIT_LEN // env.lc_obs_unit_step) + 6
    action_dim = 4

    runner = Runner(env, state_dim, action_dim)
    runner.run(env_no=global_i, random=False, save=False)

    # (data, ell_err_flag, reward0, global_index)
    return runner.data_set_arr, False, env.reward0, global_i


def run_one(local_i):
    """
    Run one environment (one lightcurve) for index local_i (0-based within the sliced range).
    Returns:
        data_set_arr: dataset generated by Runner (or None if ell_err)
        is_ell_err: True if ellipsoid initialization failed
        reward0_i: initial reward (reward0)
        global_i: global index (start_idx + local_i)
    """
    global X_total, ell_total, START_IDX, REWARD_DOMAIN, N_SET, LC_UNIT_LEN

    # Convert local index to global index
    global_i = START_IDX + local_i

    # Extract data for this index
    x = X_total[local_i]
    ell = ell_total[local_i]

    target_lc = x[:-9]
    lc_info = x[-9:]

    # Build environment
    env = AstEnv(
        target_lc=target_lc,
        lc_info=lc_info,
        reward_domain=REWARD_DOMAIN,
        N_set=N_SET,
        lc_unit_len=LC_UNIT_LEN,
        ell_init=(True, ell)
    )

    # If ellipsoid initialization fails, return flag
    if env.ell_err:
        return None, True, env.reward0, global_i

    state_dim = (env.Ntheta // env.ast_obs_unit_step) * (env.Nphi // env.ast_obs_unit_step) \
                + 2 * (LC_UNIT_LEN // env.lc_obs_unit_step) + 6
    action_dim = 4

    runner = Runner(env, state_dim, action_dim)
    runner.run(env_no=global_i, random=False, save=False)

    # (data, ell_err_flag, reward0, global_index)
    return runner.data_set_arr, False, env.reward0, global_i


def main():
    # ---- Range of global indices to compute ----
    start_idx = 1300       # inclusive
    final_idx = 1500     # exclusive (global index)
    num_samples = final_idx - start_idx

    # Number of worker processes (tune according to your CPU)
    num_workers = min(cpu_count(), 8)

    print(f"Using {num_workers} worker processes for {num_samples} samples")

    # ---- Parallel execution with multiprocessing.Pool ----
    with Pool(
        processes=num_workers,
        initializer=worker_init,
        initargs=(DATA_PATH, start_idx, final_idx, reward_domain, N_set, lightcurve_unit_len)
    ) as pool:
        # imap is a lazy iterator, results come one by one in order
        results_iter = pool.imap(run_one, range(num_samples))

        total_data_set_defined = False
        passed_idx_list = []
        reward0_list = []
        total_data_set_arr = None

        # Process results as they come in, and save every 4 samples
        for k, (data_arr, is_ell_err, reward0_i, global_i) in enumerate(
            tqdm(results_iter, total=num_samples, desc="Env parallel run")
        ):
            # k is local index: 0 .. num_samples-1

            if is_ell_err:
                # Record indices that failed ellipsoid initialization
                passed_idx_list.append(global_i)
                reward0_list.append(reward0_i)
                continue

            if not total_data_set_defined:
                total_data_set_arr = data_arr
                total_data_set_defined = True
            else:
                # Keep the original behavior: concatenate excluding the first row
                total_data_set_arr = np.concatenate(
                    (total_data_set_arr, data_arr[1:]),
                    axis=0
                )

            print("Current total_data_set_arr shape:", total_data_set_arr.shape)

            # Save and reset at chunks of 4, similar to original: if i % 4 == 0 and i != 0
            # Here (k+1) % 4 == 0 corresponds to the end of a chunk
            if (k + 1) % 4 == 0 and total_data_set_defined:
                # For file naming, we approximate the "up to" global index
                file_suffix = str(global_i + 1)

                np.save(
                    SAVE_PATH + f"data_pole_axis_RL_preset_{file_suffix}.npy",
                    total_data_set_arr
                )
                np.savez(
                    SAVE_PATH + f"data_pole_axis_RL_preset_info{file_suffix}.npz",
                    passed_idx=np.array(passed_idx_list, dtype=int),
                    reward0=np.array(reward0_list, dtype=float)
                )
                print("Saved chunk at global index", global_i + 1)
                print(total_data_set_arr.shape)

                # Reset accumulators for next chunk
                passed_idx_list = []
                reward0_list = []
                total_data_set_arr = None
                total_data_set_defined = False
                gc.collect()
                print("----- Dataset chunk separated -----")

        # If there is a remaining chunk that was not saved (when num_samples % 4 != 0)
        if total_data_set_defined and total_data_set_arr is not None:
            file_suffix = str(start_idx + num_samples)
            np.save(
                SAVE_PATH + f"data_pole_axis_RL_preset_{file_suffix}.npy",
                total_data_set_arr
            )
            np.savez(
                SAVE_PATH + f"data_pole_axis_RL_preset_info{file_suffix}.npz",
                passed_idx=np.array(passed_idx_list, dtype=int),
                reward0=np.array(reward0_list, dtype=float)
            )
            print("Saved final chunk at", start_idx + num_samples)
            print(total_data_set_arr.shape)


if __name__ == "__main__":
    # Required on Windows for multiprocessing to work correctly
    main()
